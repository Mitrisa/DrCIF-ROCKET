{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da6b78b",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87df453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 344 ms\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "# %pip install -U aeon --quiet\n",
    "# %pip install aeon[all_extras] --quiet\n",
    "# %pip install --upgrade numba --quiet\n",
    "# %pip install -U sktime --quiet\n",
    "# %pip install -U matplotlib --quiet\n",
    "# %pip install pycatch22 --quiet\n",
    "# %pip install seaborn --quiet\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sktime.datatypes._panel._convert import from_nested_to_3d_numpy\n",
    "\n",
    "from aeon.classification.interval_based import DrCIFClassifier\n",
    "from aeon.transformations.collection.convolution_based import Rocket\n",
    "# from aeon.transformations.collection.convolution_based import MiniRocket\n",
    "# from aeon.transformations.collection.convolution_based import MultiRocket\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "from aeon.testing.data_generation import make_example_3d_numpy\n",
    "from aeon.base._estimators.interval_based import BaseIntervalForest\n",
    "from aeon.classification.base import BaseClassifier\n",
    "from aeon.classification.sklearn._continuous_interval_tree import ContinuousIntervalTree\n",
    "from aeon.transformations.collection import PeriodogramTransformer\n",
    "from aeon.transformations.collection.feature_based import Catch22\n",
    "from aeon.utils.numba.general import first_order_differences_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b6bdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import aeon\n",
    "print(aeon.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f39f0a",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf186d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_DATASETS = [\n",
    "    'ArrowHead',\n",
    "    'Wine',\n",
    "    'FreezerSmallTrain',\n",
    "    'OliveOil',\n",
    "    'FordB',\n",
    "    'Car',\n",
    "    'TwoPatterns',\n",
    "    'InsectWingbeatSound',\n",
    "    'BeetleFly',\n",
    "    'Yoga',\n",
    "    'InlineSkate',\n",
    "    'FaceAll',\n",
    "    'EOGVerticalSignal',\n",
    "    'Ham',\n",
    "    'MoteStrain',\n",
    "    'ProximalPhalanxTW',\n",
    "    'WordSynonyms',\n",
    "    'Lightning7',\n",
    "    'GunPointOldVersusYoung',\n",
    "    'MelbournePedestrian',\n",
    "    'Earthquakes'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a38a44",
   "metadata": {},
   "source": [
    "## DrROCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_differences_3d(X):\n",
    "    # X must be an array 3D: (n_instances, n_channels, n_timepoints)\n",
    "    return np.diff(X, axis=2)  # difference along the time axis\n",
    "\n",
    "# --- Class definition ---\n",
    "class IntervalROCKETClassifier(BaseIntervalForest, BaseClassifier):\n",
    "    \"\"\"Interval-based classifier using ROCKET features only.\n",
    "\n",
    "    Applies ROCKET to intervals from different series representations:\n",
    "    - identity (raw series)\n",
    "    - first-order differences\n",
    "    - periodogram\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_kernels : int, dict, default=500\n",
    "        If int: same number of kernels for all representations.\n",
    "        If dict: keys = {\"identity\", \"diff\", \"periodogram\"}, values = num_kernels for each.\n",
    "    \"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:multivariate\": True,\n",
    "        \"capability:train_estimate\": True,\n",
    "        \"capability:contractable\": True,\n",
    "        \"capability:multithreading\": True,\n",
    "        \"algorithm_type\": \"interval\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_estimator=None,\n",
    "        n_estimators=50,\n",
    "        n_intervals=(4, \"sqrt-div\"),\n",
    "        min_interval_length=3,\n",
    "        max_interval_length=0.5,\n",
    "        att_subsample_size=10,\n",
    "        num_kernels=500,\n",
    "        time_limit_in_minutes=None,\n",
    "        contract_max_n_estimators=100,\n",
    "        random_state=None,\n",
    "        n_jobs=1,\n",
    "        parallel_backend=None,\n",
    "    ):\n",
    "        self.num_kernels = num_kernels\n",
    "\n",
    "        series_transformers = [\n",
    "            None,\n",
    "            FunctionTransformer(func=first_order_differences_3d, validate=False),\n",
    "            PeriodogramTransformer(),\n",
    "        ]\n",
    "\n",
    "        interval_features = [\n",
    "            Rocket(self.num_kernels) for _ in range(len(series_transformers))\n",
    "        ]\n",
    "\n",
    "        super().__init__(\n",
    "            base_estimator=base_estimator,\n",
    "            n_estimators=n_estimators,\n",
    "            interval_selection_method=\"random\",\n",
    "            n_intervals=n_intervals,\n",
    "            min_interval_length=min_interval_length,\n",
    "            max_interval_length=max_interval_length,\n",
    "            interval_features=interval_features,\n",
    "            series_transformers=series_transformers,\n",
    "            att_subsample_size=att_subsample_size,\n",
    "            replace_nan=0,\n",
    "            time_limit_in_minutes=time_limit_in_minutes,\n",
    "            contract_max_n_estimators=contract_max_n_estimators,\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs,\n",
    "            parallel_backend=parallel_backend,\n",
    "        )\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        return super()._fit(X, y)\n",
    "\n",
    "    def _predict(self, X):\n",
    "        return super()._predict(X)\n",
    "\n",
    "    def _predict_proba(self, X):\n",
    "        return super()._predict_proba(X)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_test_params(parameter_set=\"default\"):\n",
    "        if parameter_set == \"small\":\n",
    "            return {\"num_kernels\": 10}\n",
    "        elif parameter_set == \"medium\":\n",
    "            return {\"num_kernels\": 50}\n",
    "        return {\"num_kernels\": 500}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b370a",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe08bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando experimento para o dataset: ArrowHead\n",
      "Experimento para ArrowHead concluído.\n",
      "\n",
      "Executando experimento para o dataset: Wine\n",
      "Experimento para Wine concluído.\n",
      "\n",
      "Executando experimento para o dataset: FreezerSmallTrain\n",
      "Experimento para FreezerSmallTrain concluído.\n",
      "\n",
      "Executando experimento para o dataset: OliveOil\n",
      "Experimento para OliveOil concluído.\n",
      "\n",
      "Executando experimento para o dataset: FordB\n",
      "Experimento para FordB concluído.\n",
      "\n",
      "Executando experimento para o dataset: Car\n",
      "Experimento para Car concluído.\n",
      "\n",
      "Executando experimento para o dataset: TwoPatterns\n",
      "Experimento para TwoPatterns concluído.\n",
      "\n",
      "Executando experimento para o dataset: InsectWingbeatSound\n",
      "Experimento para InsectWingbeatSound concluído.\n",
      "\n",
      "Executando experimento para o dataset: BeetleFly\n",
      "Experimento para BeetleFly concluído.\n",
      "\n",
      "Executando experimento para o dataset: Yoga\n",
      "Experimento para Yoga concluído.\n",
      "\n",
      "Executando experimento para o dataset: InlineSkate\n",
      "Experimento para InlineSkate concluído.\n",
      "\n",
      "Executando experimento para o dataset: FaceAll\n",
      "Experimento para FaceAll concluído.\n",
      "\n",
      "Executando experimento para o dataset: EOGVerticalSignal\n",
      "Experimento para EOGVerticalSignal concluído.\n",
      "\n",
      "Executando experimento para o dataset: Ham\n",
      "Experimento para Ham concluído.\n",
      "\n",
      "Executando experimento para o dataset: MoteStrain\n",
      "Experimento para MoteStrain concluído.\n",
      "\n",
      "Executando experimento para o dataset: ProximalPhalanxTW\n",
      "Experimento para ProximalPhalanxTW concluído.\n",
      "\n",
      "Executando experimento para o dataset: WordSynonyms\n",
      "Experimento para WordSynonyms concluído.\n",
      "\n",
      "Executando experimento para o dataset: Lightning7\n",
      "Experimento para Lightning7 concluído.\n",
      "\n",
      "Executando experimento para o dataset: GunPointOldVersusYoung\n",
      "Experimento para GunPointOldVersusYoung concluído.\n",
      "\n",
      "Executando experimento para o dataset: MelbournePedestrian\n",
      "Experimento para MelbournePedestrian concluído.\n",
      "\n",
      "Executando experimento para o dataset: Earthquakes\n",
      "Experimento para Earthquakes concluído.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(dataset_name, num_iteracoes, resultados_path=\"res_det_4k.csv\"):\n",
    "    all_metrics = []\n",
    "    write_header = not os.path.exists(resultados_path)  # Only write the header if the file does not already exist\n",
    "\n",
    "    for i in range(num_iteracoes):\n",
    "        # print(f\"  Iteração {i + 1}/{num_iteracoes}\")\n",
    "        X_train, y_train = load_classification(dataset_name, split=\"train\")\n",
    "        X_test, y_test = load_classification(dataset_name, split=\"test\")\n",
    "\n",
    "        clf = IntervalROCKETClassifier(\n",
    "            n_estimators=50,\n",
    "            num_kernels=4,\n",
    "            att_subsample_size=None,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Measure training time\n",
    "        start_train = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_train\n",
    "\n",
    "        # Measure testing time\n",
    "        start_test = time.time()\n",
    "        y_pred = clf.predict(X_test)\n",
    "        test_time = time.time() - start_test\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "        result_dict = {\n",
    "            \"dataset\": dataset_name,\n",
    "            \"iteration\": i + 1,\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1_score\": f1,\n",
    "            \"train_time_seconds\": train_time,\n",
    "            \"test_time_seconds\": test_time\n",
    "        }\n",
    "\n",
    "        # Save to CSV immediately\n",
    "        pd.DataFrame([result_dict]).to_csv(\n",
    "            resultados_path,\n",
    "            mode=\"a\",\n",
    "            header=write_header,\n",
    "            index=False\n",
    "        )\n",
    "        write_header = False  # Only write the header the first time\n",
    "\n",
    "        all_metrics.append(result_dict)\n",
    "\n",
    "    return all_metrics\n",
    "\n",
    "# Remove the old file if you want to ensure cleanliness\n",
    "if os.path.exists(\"detailed_results_4kernels.csv\"):\n",
    "    os.remove(\"detailed_results_4kernels.csv\")\n",
    "\n",
    "# Run the experiments for all datasets\n",
    "for dataset in CHOSEN_DATASETS:\n",
    "    print(f\"Executando experimento para o dataset: {dataset}\")\n",
    "    _ = run_experiment(dataset_name=dataset, num_iteracoes=3)\n",
    "    print(f\"Experimento para {dataset} concluído.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b2ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos os experimentos foram finalizados. Resultados salvos.\n"
     ]
    }
   ],
   "source": [
    "# Reads the generated CSV and calculates the summary\n",
    "results_df = pd.read_csv(\"detailed_results_4kernels.csv\")\n",
    "\n",
    "summary = results_df.groupby(\"dataset\").agg(\n",
    "    accuracy_mean=(\"accuracy\", \"mean\"),\n",
    "    accuracy_std=(\"accuracy\", \"std\"),\n",
    "    accuracy_min=(\"accuracy\", \"min\"),\n",
    "    accuracy_max=(\"accuracy\", \"max\"),\n",
    "    precision_mean=(\"precision\", \"mean\"),\n",
    "    precision_std=(\"precision\", \"std\"),\n",
    "    recall_mean=(\"recall\", \"mean\"),\n",
    "    recall_std=(\"recall\", \"std\"),\n",
    "    f1_mean=(\"f1_score\", \"mean\"),\n",
    "    f1_std=(\"f1_score\", \"std\"),\n",
    "    train_time_mean=(\"train_time_seconds\", \"mean\"),\n",
    "    train_time_std=(\"train_time_seconds\", \"std\"),\n",
    "    test_time_mean=(\"test_time_seconds\", \"mean\"),\n",
    "    test_time_std=(\"test_time_seconds\", \"std\")\n",
    ").reset_index()\n",
    "\n",
    "# Save final summary\n",
    "summary.to_csv(\"4kernels_summary_results.csv\", index=False)\n",
    "\n",
    "print(\"All experiments have been completed. Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
